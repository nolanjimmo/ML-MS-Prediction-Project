{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbae6aa9",
   "metadata": {},
   "source": [
    "Notebook for our final project!\n",
    "\n",
    "Team:\n",
    "Nolan Jimmo\n",
    "Nicole Donahue\n",
    "Frederick Carlson\n",
    "Xinyu Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817b4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports, function def and some file reading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def conf_matrix_to_df(conf_matrix, target_names):\n",
    "    return pd.DataFrame(conf_matrix, columns=target_names, index=target_names)\n",
    "\n",
    "\n",
    "#reading in EDSS Score data\n",
    "EDSS_FILENAME = \"data/EDSS_Scores.csv\"\n",
    "EDSS_scores = pd.read_csv(EDSS_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48456703",
   "metadata": {},
   "source": [
    "Find the subject ids that have valid EDSS scores to be able to just train model on these subjects data. Storing the valid subject id and scores in a dictionary with the structure: {Subject ID: (baseline score, 6mo score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b631b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sids = {}\n",
    "for i, row in EDSS_scores.iterrows():\n",
    "    if type(row[\"Subject ID \"]) == float:\n",
    "        break\n",
    "    if row[\"EDSS Baseline (Score out of 10) \"] != np.NaN and row[\"EDSS 6mo (Score out of 10) \"] != np.NaN:\n",
    "        valid_sids[(row[\"Subject ID \"])] = (str(row[\"EDSS Baseline (Score out of 10) \"]), str(row[\"EDSS 6mo (Score out of 10) \"]))\n",
    "#print(valid_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca0fbe",
   "metadata": {},
   "source": [
    "converting regular EDSS scores to the binary 0, or 1, for low vs. moderate/severe EDSS score. Everything up to 4 will be 0, everything 4 and above will be moderate/severe score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e6ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sids_generalized = {}\n",
    "for key, value in valid_sids.items():\n",
    "    if float(value[0]) < 4:\n",
    "        v1 = 0\n",
    "    else:\n",
    "        v1 = 1\n",
    "    if float(value[1]) < 4:\n",
    "        v2 = 0\n",
    "    else:\n",
    "        v2 = 0\n",
    "    valid_sids_generalized[key] = (v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d6eb6",
   "metadata": {},
   "source": [
    "Get filenames for the valid subject data files out of the data folder, for both the baseline and 6mo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23510d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here, it is the baseline of the gait data\n",
    "gait_baseline_filenames = glob.glob(\"data/Processed Data - MS +/Gait/MS1 Session 1/*\")\n",
    "#print((gait_baseline_filenames))\n",
    "removal = []\n",
    "for g in gait_baseline_filenames:\n",
    "    if g[-9:-4] not in valid_sids_generalized.keys():\n",
    "        removal.append(g)\n",
    "\n",
    "gait_b_filenames = [l for l in gait_baseline_filenames if l not in removal]\n",
    "\n",
    "###NOTE: In this test below, sometimes the two lists are not the same length\n",
    "# HOWEVER, the valid EDSS subject ids list is always longer, so we will always have a\n",
    "# \"target\" for each feature set, so we should be good to go\n",
    "#print(len(gait_b_filenames), len(valid_sids.keys()))\n",
    "\n",
    "\n",
    "# here, it is the 6mo of the gait data\n",
    "gait_6mo_filenames = glob.glob(\"data/Processed Data - MS +/Gait/MS1 Session 2/*\")\n",
    "#print((gait_baseline_filenames))\n",
    "removal = []\n",
    "for g in gait_baseline_filenames:\n",
    "    if g[-9:-4] not in valid_sids_generalized.keys():\n",
    "        removal.append(g)\n",
    "\n",
    "gait_6_filenames = [l for l in gait_baseline_filenames if l not in removal]\n",
    "\n",
    "# Now, loop through the valid files, get the features from each valid subject and assign\n",
    "# their EDSS score as the \"target\"\n",
    "valid_subject_data = []\n",
    "cols = []\n",
    "for g in gait_b_filenames:\n",
    "    with open(g, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        if cols == []:\n",
    "            cols = next(file).strip().split(',')\n",
    "            cols.append('target')\n",
    "        for row in reader:\n",
    "            if row[0] != 'timestamp_start':\n",
    "                row.append(valid_sids_generalized[g[-9:-4]][0])\n",
    "                valid_subject_data.append(row)\n",
    "\n",
    "# doing the exact some thing as before, just with the 6 month data\n",
    "# We can just add this data straight to the valid_subject_data list because it is all going\n",
    "# to be training data\n",
    "# We do have to separate the for loops though because we have to add the proper EDSS value\n",
    "# from the valid_sids dictionary\n",
    "for g6 in gait_6mo_filenames:\n",
    "    with open(g6, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        if cols == []:\n",
    "            cols = next(file).strip().split(',')\n",
    "            cols.append('target')\n",
    "        for row in reader:\n",
    "            if row[0] != 'timestamp_start':\n",
    "                row.append(valid_sids_generalized[g[-9:-4]][1])\n",
    "                valid_subject_data.append(row)\n",
    "#print(cols)\n",
    "#print(valid_subject_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23ef6a",
   "metadata": {},
   "source": [
    "Final setup for the features dataframe and then training/testing the SVM model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06358237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "predicting\n",
      "\n",
      "Printing confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1\n",
       "0  1878  0\n",
       "1    20  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(valid_subject_data, columns=cols)\n",
    "#print(df)\n",
    "df.drop(df.columns[[0,1,2,9,10,13]], axis=1, inplace=True)\n",
    "#print(df)\n",
    "\n",
    "#Train the model and see what happens!\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:, df.columns != 'target'], np.array(df.iloc[:, df.columns == 'target']).reshape(9486,), test_size = 0.2, random_state = 0)\n",
    "svm = SVC(kernel=\"poly\")\n",
    "#print(set(y_test))\n",
    "#print(x_train, y_train)\n",
    "print('training')\n",
    "svm.fit(x_train, y_train)\n",
    "print(\"predicting\")\n",
    "svm_y_predict = svm.predict(x_test)\n",
    "\n",
    "conf_matrix_svm = confusion_matrix(y_test, svm_y_predict)\n",
    "print(\"\\nPrinting confusion matrix\")\n",
    "conf_matrix_to_df(conf_matrix_svm, [0,1])\n",
    "#print(conf_matrix_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
